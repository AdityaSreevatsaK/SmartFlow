# TODO List

---

## ✅ Phase 1: Literature Survey
- [ ] Collect at least 50 research papers
- [ ] Create summary sheet of each paper
- [ ] Categorise algorithms used (e.g., DQN, PPO, etc.)
- [ ] Note simulation environments, datasets used
- [ ] Write 1st draft of Literature Review section

---

## ✅ Phase 2: Foundations
- [ ] Finalise simulation environment (SUMO / Grid-based / Custom)
- [ ] Define action, state, and reward for the RL setup
- [ ] Prepare small synthetic dataset for testing
- [ ] Familiarise team with Stable-Baselines3 and Gym
- [ ] Create RL environment class

---

## ✅ Phase 3: Basic Model Building
- [ ] Implement Q-learning/DQN agents
- [ ] Train agents on basic environment
- [ ] Plot reward curves
- [ ] Compare performance to naive random policy
- [ ] Add model logs and visuals to `results/`

---

## ✅ Phase 4: Customise and Fine-Tune Model
- [ ] Refine reward function (include profit, idle time etc.)
- [ ] Experiment with PPO/A2C using Stable-Baselines3
- [ ] Hyperparameter tuning
- [ ] Log performance improvements
- [ ] Build final demo (interactive notebook/script)

---

## ✅ Phase 5: Final Paper Submission
- [ ] Finalise all sections of paper
- [ ] Proofread and format as per conference template
- [ ] Prepare slide deck for presentation
- [ ] Submit paper to conference/journal
- [ ] Practice and record demo if required
